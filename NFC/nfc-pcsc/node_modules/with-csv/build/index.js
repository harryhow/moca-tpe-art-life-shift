"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.withCSV = void 0;
const crypto_1 = require("crypto");
const fs_1 = __importDefault(require("fs"));
const lodash_pick_1 = __importDefault(require("lodash.pick"));
const lodash_isequal_1 = __importDefault(require("lodash.isequal"));
const csv_parser_1 = __importDefault(require("csv-parser"));
const stream_1 = require("stream");
const berror_1 = require("berror");
const hashCache = new Set();
function withCSV(csvFileOrBuffer, options) {
    let stream = undefined;
    if (typeof csvFileOrBuffer === 'string') {
        stream = fs_1.default.createReadStream(csvFileOrBuffer, { encoding: 'utf-8' });
    }
    else if (csvFileOrBuffer instanceof Buffer) {
        // Why Readable, _read, push(null) ? See this: https://stackoverflow.com/a/44091532
        stream = new stream_1.Readable();
        stream._read = () => { }; // noop
        stream.push(csvFileOrBuffer);
        stream.push(null);
    }
    if (!stream) {
        throw new berror_1.BError('Input should be a string path or a buffer', undefined, { csvFileOrBuffer });
    }
    const readInterface = stream.pipe((0, csv_parser_1.default)(options));
    const pipeline = [];
    function getQueryChain() {
        async function applyPipeline(row, idx) {
            let finalValue = row;
            // First apply the pipeline to each row to filter/map it
            let finishedTheChain = true;
            for (const operation of pipeline) {
                const { continueChain, value } = await operation(finalValue, idx);
                finalValue = value;
                if (!continueChain) {
                    return { finishedTheChain: false, value: finalValue };
                }
            }
            return { finishedTheChain, value: finalValue };
        }
        async function toDataset() {
            const dataSet = [];
            let idx = 0;
            for await (const row of readInterface) {
                const { finishedTheChain, value } = await applyPipeline(row, idx);
                if (finishedTheChain) {
                    dataSet.push(value);
                }
                idx++;
            }
            return dataSet;
        }
        const queryChain = {
            /**
             * Chainable methods
             */
            uniq(callback) {
                pipeline.push(async function uniq_(value, index) {
                    const hash = (0, crypto_1.createHash)('sha1');
                    const rowToHash = callback ? await callback(value, index) : value;
                    hash.update(JSON.stringify(rowToHash), 'utf8');
                    const hashedRow = hash.digest('hex');
                    if (!hashCache.has(hashedRow)) {
                        hashCache.add(hashedRow);
                        return { continueChain: true, value };
                    }
                    return { continueChain: false, value: null };
                });
                hashCache.clear();
                return getQueryChain();
            },
            filter(callback) {
                pipeline.push(async function filter_(value, index) {
                    if (await callback(value, index)) {
                        return { continueChain: true, value };
                    }
                    return { continueChain: false, value: null };
                });
                return getQueryChain();
            },
            map(callback) {
                pipeline.push(async function map_(value, index) {
                    return {
                        continueChain: true,
                        value: await callback(value, index),
                    };
                });
                return getQueryChain();
            },
            forEach(callback) {
                pipeline.push(async function forEach_(value, index) {
                    await callback(value, index);
                    return { continueChain: true, value };
                });
                return getQueryChain();
            },
            /**
             * Terminator methods
             */
            async find(callback) {
                let idx = 0;
                for await (const row of readInterface) {
                    // Apply the pipeline to see if the row is filtered out
                    const { finishedTheChain, value } = await applyPipeline(row, idx);
                    // Row has finished the chain so it hasn't been filtered out,
                    // Apply the find and stop reading rows
                    if (finishedTheChain && (await callback(value))) {
                        return value;
                    }
                    idx++;
                }
                return null;
            },
            async every(callback) {
                let idx = 0;
                for await (const row of readInterface) {
                    // Apply the pipeline to see if the row is filtered out
                    const { finishedTheChain, value } = await applyPipeline(row, idx);
                    if (finishedTheChain && !(await callback(value))) {
                        return false;
                    }
                    idx++;
                }
                return true;
            },
            async some(callback) {
                let idx = 0;
                for await (const row of readInterface) {
                    // Apply the pipeline to see if the row is filtered out
                    const { finishedTheChain, value } = await applyPipeline(row, idx);
                    if (finishedTheChain && (await callback(value))) {
                        return true;
                    }
                    idx++;
                }
                return false;
            },
            async includes(searchedValue) {
                let idx = 0;
                for await (const row of readInterface) {
                    // Apply the pipeline to see if the row is filtered out
                    const { finishedTheChain, value } = await applyPipeline(row, idx);
                    // Row has finished the chain so it hasn't been filtered out,
                    // Perform isEqual, stop reading rows if found
                    if (finishedTheChain && (0, lodash_isequal_1.default)(value, searchedValue)) {
                        return true;
                    }
                    idx++;
                }
                return false;
            },
            async toArray() {
                return toDataset();
            },
            async toJSON(space) {
                const dataSet = await toDataset();
                return JSON.stringify(dataSet, null, space);
            },
            async process() {
                let idx = 0;
                for await (const row of readInterface) {
                    await applyPipeline(row, idx);
                    idx++;
                }
            },
        };
        return queryChain;
    }
    return {
        async get(columns) {
            const queryChain = getQueryChain();
            if (columns && columns.length > 0) {
                queryChain.map(value => (0, lodash_pick_1.default)(value, columns));
            }
            return queryChain.toArray();
        },
        query(columns) {
            const queryChain = getQueryChain();
            if (columns && columns.length > 0) {
                queryChain.map(value => (0, lodash_pick_1.default)(value, columns));
            }
            return queryChain;
        },
    };
}
exports.withCSV = withCSV;
//# sourceMappingURL=index.js.map